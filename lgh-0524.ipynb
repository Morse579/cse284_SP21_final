{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "informational-approach",
   "metadata": {},
   "source": [
    "### random vs info_gain vs chi2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "generous-battlefield",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import os\n",
    "import pandas as pd\n",
    "    \n",
    "geno = np.loadtxt('/datasets/cs284-sp21-A00-public/ps2/precomputed/ps2_pca.genotypes.tab') # (28622 SNPs, 2504 people)\n",
    "pop_6 = np.load('pop_6.npy')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "prime-nothing",
   "metadata": {},
   "outputs": [],
   "source": [
    "train = geno[:,:2000]\n",
    "test = geno[:,2000:]\n",
    "train_Y = np.array(pop_6[:2000])\n",
    "test_Y = np.array(pop_6[2000:])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "widespread-mirror",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn import svm\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn import tree\n",
    "from sklearn.ensemble import  AdaBoostClassifier\n",
    "from sklearn.naive_bayes import MultinomialNB\n",
    "\n",
    "import time\n",
    "\n",
    "\n",
    "def simple_SVM(X,Y,test_X,test_Y,method='svm_linear'):\n",
    "    time0=time.time()\n",
    "    if method=='svm_linear' or method==0:\n",
    "        clf = svm.SVC(kernel='linear')\n",
    "    elif method=='KNeighbors' or method==1:\n",
    "        clf = KNeighborsClassifier()\n",
    "    elif method=='LogisticRegression' or method==2:\n",
    "        clf = LogisticRegression(penalty='l2')\n",
    "    elif method=='RandomForest' or method==3:\n",
    "        clf = RandomForestClassifier(n_estimators=8)\n",
    "    elif method=='DecisionTree' or method==4:\n",
    "        clf = tree.DecisionTreeClassifier()\n",
    "    elif method=='AdaBoost' or method==5:\n",
    "        clf = AdaBoostClassifier()\n",
    "    elif method=='Bayes' or method==6:\n",
    "        clf = MultinomialNB(alpha=0.01)\n",
    "    else:\n",
    "        print('Not implied!')\n",
    "        return None\n",
    "    \n",
    "    clf.fit(X,Y)\n",
    "    \n",
    "    print('Train time:',int(time.time()-time0))\n",
    "    \n",
    "    print('train acc:',clf.score(X, Y))\n",
    "    print('test acc:',clf.score(test_X, test_Y))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "described-unemployment",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "snps: 10\n",
      "Train time: 0\n",
      "train acc: 0.5565\n",
      "test acc: 0.4801587301587302\n",
      "Train time: 0\n",
      "train acc: 0.6035\n",
      "test acc: 0.37103174603174605\n",
      "Train time: 0\n",
      "train acc: 0.5605\n",
      "test acc: 0.4662698412698413\n",
      "Train time: 0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/conda/lib/python3.8/site-packages/sklearn/linear_model/_logistic.py:763: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train acc: 0.753\n",
      "test acc: 0.3968253968253968\n",
      "Train time: 0\n",
      "train acc: 0.7645\n",
      "test acc: 0.3888888888888889\n",
      "Train time: 0\n",
      "train acc: 0.3395\n",
      "test acc: 0.3611111111111111\n",
      "Train time: 0\n",
      "train acc: 0.5185\n",
      "test acc: 0.4226190476190476\n",
      "\n",
      "snps: 50\n",
      "Train time: 0\n",
      "train acc: 0.8565\n",
      "test acc: 0.6746031746031746\n",
      "Train time: 0\n",
      "train acc: 0.7915\n",
      "test acc: 0.5654761904761905\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/conda/lib/python3.8/site-packages/sklearn/linear_model/_logistic.py:763: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train time: 7\n",
      "train acc: 0.8385\n",
      "test acc: 0.6309523809523809\n",
      "Train time: 0\n",
      "train acc: 0.99\n",
      "test acc: 0.5952380952380952\n",
      "Train time: 0\n",
      "train acc: 1.0\n",
      "test acc: 0.4742063492063492\n",
      "Train time: 0\n",
      "train acc: 0.353\n",
      "test acc: 0.23809523809523808\n",
      "Train time: 0\n",
      "train acc: 0.8035\n",
      "test acc: 0.7003968253968254\n",
      "\n"
     ]
    }
   ],
   "source": [
    "## random\n",
    "import random\n",
    "for num in [10,50]:\n",
    "    print('snps:',num)\n",
    "    rl = random.sample(range(28622), num)\n",
    "    simple_SVM(train[rl,:].T,train_Y,test[rl,:].T,test_Y)\n",
    "    simple_SVM(train[rl,:].T,train_Y,test[rl,:].T,test_Y,1)\n",
    "    simple_SVM(train[rl,:].T,train_Y,test[rl,:].T,test_Y,2)\n",
    "    simple_SVM(train[rl,:].T,train_Y,test[rl,:].T,test_Y,3)\n",
    "    simple_SVM(train[rl,:].T,train_Y,test[rl,:].T,test_Y,4)\n",
    "    simple_SVM(train[rl,:].T,train_Y,test[rl,:].T,test_Y,5)\n",
    "    simple_SVM(train[rl,:].T,train_Y,test[rl,:].T,test_Y,6)\n",
    "    print('')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "described-occasions",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "snps: 10\n",
      "Train time: 0\n",
      "train acc: 0.5655\n",
      "test acc: 0.5138888888888888\n",
      "Train time: 0\n",
      "train acc: 0.552\n",
      "test acc: 0.375\n",
      "Train time: 0\n",
      "train acc: 0.5775\n",
      "test acc: 0.4861111111111111\n",
      "Train time: 0\n",
      "train acc: 0.6915\n",
      "test acc: 0.48214285714285715\n",
      "Train time: 0\n",
      "train acc: 0.702\n",
      "test acc: 0.46825396825396826\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/conda/lib/python3.8/site-packages/sklearn/linear_model/_logistic.py:763: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train time: 0\n",
      "train acc: 0.318\n",
      "test acc: 0.36507936507936506\n",
      "Train time: 0\n",
      "train acc: 0.5245\n",
      "test acc: 0.4662698412698413\n",
      "\n",
      "snps: 50\n",
      "Train time: 0\n",
      "train acc: 0.8325\n",
      "test acc: 0.7222222222222222\n",
      "Train time: 0\n",
      "train acc: 0.7815\n",
      "test acc: 0.6091269841269841\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/conda/lib/python3.8/site-packages/sklearn/linear_model/_logistic.py:763: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train time: 7\n",
      "train acc: 0.8185\n",
      "test acc: 0.7242063492063492\n",
      "Train time: 0\n",
      "train acc: 0.9825\n",
      "test acc: 0.6349206349206349\n",
      "Train time: 0\n",
      "train acc: 1.0\n",
      "test acc: 0.5\n",
      "Train time: 0\n",
      "train acc: 0.358\n",
      "test acc: 0.16666666666666666\n",
      "Train time: 0\n",
      "train acc: 0.788\n",
      "test acc: 0.7281746031746031\n",
      "\n"
     ]
    }
   ],
   "source": [
    "## info_gain\n",
    "from collections import defaultdict\n",
    "from math import log\n",
    "\n",
    "def calcShannonEnt(Y):\n",
    "    numEntries = len(Y)\n",
    "    labelCounts = defaultdict(int)\n",
    "    for label in Y:\n",
    "        labelCounts[label] += 1\n",
    "    shannonEnt = 0.0\n",
    "    for key in labelCounts:\n",
    "        prob = float(labelCounts[key])/numEntries\n",
    "        shannonEnt -= prob * log(prob, 2)\n",
    "    return shannonEnt\n",
    "\n",
    "def calcInfoGain(dataset,Y):\n",
    "    baseEntropy = calcShannonEnt(Y)\n",
    "    InfoGain_list = []\n",
    "    for i in range(dataset.shape[0]):\n",
    "        subset_list = [[],[],[]]\n",
    "        for j in range(dataset.shape[1]):\n",
    "            subset_list[int(dataset[i,j])].append(j)\n",
    "        newEntropy = 0.0\n",
    "        splitInfo = 0.0\n",
    "        for value in [0,1,2]:\n",
    "            if len(subset_list[value])==0:\n",
    "                continue\n",
    "            prob = len(subset_list[value])/float(dataset.shape[1])\n",
    "            newEntropy += prob * calcShannonEnt(Y[subset_list[value]])\n",
    "            splitInfo += -prob * log(prob, 2)\n",
    "        infoGain = baseEntropy - newEntropy\n",
    "        if (splitInfo == 0):\n",
    "            continue\n",
    "        infoGainRatio = infoGain / splitInfo\n",
    "        InfoGain_list.append(infoGainRatio)\n",
    "    return InfoGain_list\n",
    "\n",
    "InfoGain_list = calcInfoGain(train,train_Y)\n",
    "rank_infoGain = np.array(InfoGain_list).argsort()\n",
    "\n",
    "for num in [10,50]:\n",
    "    \n",
    "    print('snps:',num)\n",
    "    simple_SVM(train[rank_infoGain[-num:],:].T,train_Y,test[rank_infoGain[-num:],:].T,test_Y,0)\n",
    "    simple_SVM(train[rank_infoGain[-num:],:].T,train_Y,test[rank_infoGain[-num:],:].T,test_Y,1)\n",
    "    simple_SVM(train[rank_infoGain[-num:],:].T,train_Y,test[rank_infoGain[-num:],:].T,test_Y,2)\n",
    "    simple_SVM(train[rank_infoGain[-num:],:].T,train_Y,test[rank_infoGain[-num:],:].T,test_Y,3)\n",
    "    simple_SVM(train[rank_infoGain[-num:],:].T,train_Y,test[rank_infoGain[-num:],:].T,test_Y,4)\n",
    "    simple_SVM(train[rank_infoGain[-num:],:].T,train_Y,test[rank_infoGain[-num:],:].T,test_Y,5)\n",
    "    simple_SVM(train[rank_infoGain[-num:],:].T,train_Y,test[rank_infoGain[-num:],:].T,test_Y,6)\n",
    "    print('')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "biblical-carolina",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "snps: 10\n",
      "Train time: 0\n",
      "train acc: 0.661\n",
      "test acc: 0.5972222222222222\n",
      "Train time: 0\n",
      "train acc: 0.5915\n",
      "test acc: 0.5297619047619048\n",
      "Train time: 0\n",
      "train acc: 0.6685\n",
      "test acc: 0.5833333333333334\n",
      "Train time: 0\n",
      "train acc: 0.7205\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/conda/lib/python3.8/site-packages/sklearn/linear_model/_logistic.py:763: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "test acc: 0.5615079365079365\n",
      "Train time: 0\n",
      "train acc: 0.723\n",
      "test acc: 0.5555555555555556\n",
      "Train time: 0\n",
      "train acc: 0.525\n",
      "test acc: 0.44841269841269843\n",
      "Train time: 0\n",
      "train acc: 0.543\n",
      "test acc: 0.48214285714285715\n",
      "\n",
      "snps: 50\n",
      "Train time: 0\n",
      "train acc: 0.8625\n",
      "test acc: 0.7400793650793651\n",
      "Train time: 0\n",
      "train acc: 0.8245\n",
      "test acc: 0.6924603174603174\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/conda/lib/python3.8/site-packages/sklearn/linear_model/_logistic.py:763: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train time: 7\n",
      "train acc: 0.8605\n",
      "test acc: 0.7400793650793651\n",
      "Train time: 0\n",
      "train acc: 0.964\n",
      "test acc: 0.6805555555555556\n",
      "Train time: 0\n",
      "train acc: 0.976\n",
      "test acc: 0.6369047619047619\n",
      "Train time: 0\n",
      "train acc: 0.6305\n",
      "test acc: 0.45436507936507936\n",
      "Train time: 0\n",
      "train acc: 0.778\n",
      "test acc: 0.7043650793650794\n",
      "\n",
      "snps: 100\n",
      "Train time: 0\n",
      "train acc: 0.903\n",
      "test acc: 0.7321428571428571\n",
      "Train time: 0\n",
      "train acc: 0.8255\n",
      "test acc: 0.6984126984126984\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/conda/lib/python3.8/site-packages/sklearn/linear_model/_logistic.py:763: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train time: 9\n",
      "train acc: 0.892\n",
      "test acc: 0.7242063492063492\n",
      "Train time: 0\n",
      "train acc: 0.9865\n",
      "test acc: 0.7202380952380952\n",
      "Train time: 0\n",
      "train acc: 0.9985\n",
      "test acc: 0.6388888888888888\n",
      "Train time: 0\n",
      "train acc: 0.5505\n",
      "test acc: 0.44047619047619047\n",
      "Train time: 0\n",
      "train acc: 0.7995\n",
      "test acc: 0.7301587301587301\n",
      "\n",
      "snps: 500\n",
      "Train time: 0\n",
      "train acc: 1.0\n",
      "test acc: 0.7837301587301587\n",
      "Train time: 0\n",
      "train acc: 0.891\n",
      "test acc: 0.8194444444444444\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/conda/lib/python3.8/site-packages/sklearn/linear_model/_logistic.py:763: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train time: 15\n",
      "train acc: 1.0\n",
      "test acc: 0.7936507936507936\n",
      "Train time: 0\n",
      "train acc: 0.994\n",
      "test acc: 0.751984126984127\n",
      "Train time: 0\n",
      "train acc: 1.0\n",
      "test acc: 0.7123015873015873\n",
      "Train time: 0\n",
      "train acc: 0.609\n",
      "test acc: 0.5257936507936508\n",
      "Train time: 0\n",
      "train acc: 0.9035\n",
      "test acc: 0.8511904761904762\n",
      "\n",
      "snps: 1000\n",
      "Train time: 0\n",
      "train acc: 1.0\n",
      "test acc: 0.8492063492063492\n",
      "Train time: 0\n",
      "train acc: 0.8945\n",
      "test acc: 0.8293650793650794\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/conda/lib/python3.8/site-packages/sklearn/linear_model/_logistic.py:763: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train time: 21\n",
      "train acc: 1.0\n",
      "test acc: 0.8392857142857143\n",
      "Train time: 0\n",
      "train acc: 0.9965\n",
      "test acc: 0.8154761904761905\n",
      "Train time: 0\n",
      "train acc: 1.0\n",
      "test acc: 0.7301587301587301\n",
      "Train time: 1\n",
      "train acc: 0.579\n",
      "test acc: 0.501984126984127\n",
      "Train time: 0\n",
      "train acc: 0.9345\n",
      "test acc: 0.8928571428571429\n",
      "\n"
     ]
    }
   ],
   "source": [
    "## chi2\n",
    "from sklearn.feature_selection import SelectKBest\n",
    "from sklearn.feature_selection import chi2\n",
    "\n",
    "for num in [10,50,100,500,1000]:\n",
    "    print('snps:',num)\n",
    "    chi2_selection = SelectKBest(chi2, k=num).fit(train.T, np.array(train_Y))\n",
    "    X_select_index = chi2_selection.get_support(indices=True)\n",
    "    \n",
    "    simple_SVM(train[X_select_index,:].T,train_Y,test[X_select_index,:].T,test_Y,0)\n",
    "    simple_SVM(train[X_select_index,:].T,train_Y,test[X_select_index,:].T,test_Y,1)\n",
    "    simple_SVM(train[X_select_index,:].T,train_Y,test[X_select_index,:].T,test_Y,2)\n",
    "    simple_SVM(train[X_select_index,:].T,train_Y,test[X_select_index,:].T,test_Y,3)\n",
    "    simple_SVM(train[X_select_index,:].T,train_Y,test[X_select_index,:].T,test_Y,4)\n",
    "    simple_SVM(train[X_select_index,:].T,train_Y,test[X_select_index,:].T,test_Y,5)\n",
    "    simple_SVM(train[X_select_index,:].T,train_Y,test[X_select_index,:].T,test_Y,6)\n",
    "    print('')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "promising-drain",
   "metadata": {},
   "source": [
    "Format:  \n",
    "snp number  \n",
    "(left: random; middle: info_gain; right: chi2)  \n",
    "0 svm_linear  \n",
    "1 KNeighbors  \n",
    "2 LogisticRegression  \n",
    "3 RandomForest  \n",
    "4 DecisionTree  \n",
    "5 AdaBoost  \n",
    "6 Bayes  \n",
    "\n",
    "\n",
    "10  \n",
    "0.44 0.51 0.59  \n",
    "0.32 0.37 0.52  \n",
    "0.44 0.48 0.58  \n",
    "0.37 0.46 0.58  \n",
    "0.34 0.46 0.54  \n",
    "0.18 0.36 0.44  \n",
    "0.41 0.46 0.48  \n",
    "\n",
    "50  \n",
    "0.64 0.72 0.74  \n",
    "0.57 0.60 0.69  \n",
    "0.66 0.72 0.74  \n",
    "0.51 0.61 0.69  \n",
    "0.42 0.50 0.64  \n",
    "0.51 0.16 0.45  \n",
    "0.65 0.72 0.70  \n",
    "\n",
    "100  \n",
    "0.71 0.75 0.73  \n",
    "0.69 0.70 0.69  \n",
    "0.72 0.76 0.72  \n",
    "0.62 0.63 0.72  \n",
    "0.50 0.52 0.65  \n",
    "0.22 0.29 0.44  \n",
    "0.78 0.79 0.73\n",
    "\n",
    "500  \n",
    "0.79 0.79 0.78  \n",
    "0.84 0.84 0.81  \n",
    "0.79 0.81 0.79  \n",
    "0.73 0.72 0.77  \n",
    "0.62 0.64 0.72  \n",
    "0.33 0.39 0.82  \n",
    "0.87 0.89 0.85  \n",
    "\n",
    "1000  \n",
    "0.82 0.82 0.84  \n",
    "0.84 0.87 0.82  \n",
    "0.83 0.85 0.83  \n",
    "0.75 0.75 0.78  \n",
    "0.66 0.67 0.75  \n",
    "0.53 0.54 0.50  \n",
    "0.87 0.90 0.89"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "aggregate-weapon",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
