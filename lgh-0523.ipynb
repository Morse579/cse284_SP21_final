{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "complex-issue",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import os\n",
    "import pandas as pd\n",
    "from sklearn import svm\n",
    "import time\n",
    "\n",
    "geno = np.loadtxt('/datasets/cs284-sp21-A00-public/ps2/precomputed/ps2_pca.genotypes.tab') # (28622 SNPs, 2504 people)\n",
    "pop_6 = np.load('pop_6.npy')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "vanilla-complement",
   "metadata": {},
   "outputs": [],
   "source": [
    "train = geno[:,:2000]\n",
    "test = geno[:,2000:]\n",
    "train_Y = pop_6[:2000]\n",
    "test_Y = pop_6[2000:]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "advisory-degree",
   "metadata": {},
   "source": [
    "数据集0.8/0.2划分，可以尝试些别的分类算法。直接在整个数据集上run的时间非常长(可能是datahub或svm的原因)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "greenhouse-thanks",
   "metadata": {},
   "outputs": [],
   "source": [
    "def simple_SVM(X,Y,test_X,test_Y):\n",
    "    time0=time.time()\n",
    "    \n",
    "    clf = svm.SVC(kernel='linear')\n",
    "    clf.fit(X,Y)\n",
    "    \n",
    "    print('Train time:',time.time()-time0)\n",
    "    \n",
    "    print('train acc:',clf.score(X, Y))\n",
    "    print('test acc:',clf.score(test_X, test_Y))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "private-least",
   "metadata": {},
   "outputs": [],
   "source": [
    "# simple_SVM(train.T,train_Y,test.T,test_Y)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "alien-original",
   "metadata": {},
   "source": [
    "### chi2 selection"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "south-digest",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Time: 1.5748379230499268\n",
      "Train time: 4.332159519195557\n",
      "train acc: 1.0\n",
      "test acc: 0.9027777777777778\n"
     ]
    }
   ],
   "source": [
    "from sklearn.feature_selection import SelectKBest\n",
    "from sklearn.feature_selection import chi2\n",
    "\n",
    "time1 = time.time()\n",
    "chi2_selection = SelectKBest(chi2, k=5000).fit(train.T, np.array(train_Y))\n",
    "X_select_index = chi2_selection.get_support(indices=True)\n",
    "print('Time:',time.time()-time1)\n",
    "simple_SVM(train[X_select_index,:].T,train_Y,test[X_select_index,:].T,test_Y)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "varied-antibody",
   "metadata": {},
   "source": [
    "### pca comparison"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "traditional-catalog",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "pca time: 34.71433424949646\n",
      "Train time: 0.14259600639343262\n",
      "train acc: 0.9555\n",
      "test acc: 0.9226190476190477\n"
     ]
    }
   ],
   "source": [
    "from sklearn.decomposition import PCA\n",
    "\n",
    "time1=time.time()\n",
    "\n",
    "pca = PCA(n_components=4).fit(train.T)\n",
    "train_pca = pca.transform(train.T)\n",
    "test_pca = pca.transform(test.T)\n",
    "\n",
    "print('pca time:',time.time()-time1)\n",
    "\n",
    "simple_SVM(train_pca,train_Y,test_pca,test_Y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "extensive-cable",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "preprocess time: 10.013997554779053\n",
      "Train time: 0.24165749549865723\n",
      "train acc: 0.9495\n",
      "test acc: 0.9126984126984127\n",
      "preprocess time: 15.121902465820312\n",
      "Train time: 0.14634490013122559\n",
      "train acc: 0.9525\n",
      "test acc: 0.9206349206349206\n",
      "preprocess time: 31.267665147781372\n",
      "Train time: 0.222670316696167\n",
      "train acc: 0.9535\n",
      "test acc: 0.9186507936507936\n"
     ]
    }
   ],
   "source": [
    "for thres in [5000,10000,15000]:\n",
    "    time1=time.time()\n",
    "    \n",
    "    chi2_selection = SelectKBest(chi2, k=thres).fit(train.T, np.array(train_Y))\n",
    "    X_select_index = chi2_selection.get_support(indices=True)\n",
    "    \n",
    "    pca = PCA(n_components=4).fit(train[X_select_index].T)\n",
    "    train_pca = pca.transform(train[X_select_index].T)\n",
    "    test_pca = pca.transform(test[X_select_index].T)\n",
    "    \n",
    "    print('preprocess time:',time.time()-time1)\n",
    "\n",
    "    simple_SVM(train_pca,train_Y,test_pca,test_Y)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "everyday-eclipse",
   "metadata": {},
   "source": [
    "### InfoGain"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "overhead-footwear",
   "metadata": {},
   "outputs": [],
   "source": [
    "from collections import defaultdict\n",
    "from math import log\n",
    "\n",
    "def calcShannonEnt(Y):\n",
    "    numEntries = len(Y)\n",
    "    labelCounts = defaultdict(int)\n",
    "    for label in Y:\n",
    "        labelCounts[label] += 1\n",
    "    shannonEnt = 0.0\n",
    "    for key in labelCounts:\n",
    "        prob = float(labelCounts[key])/numEntries\n",
    "        shannonEnt -= prob * log(prob, 2)\n",
    "    return shannonEnt\n",
    "\n",
    "def calcInfoGain(dataset,Y):\n",
    "    baseEntropy = calcShannonEnt(Y)\n",
    "    InfoGain_list = []\n",
    "    for i in range(dataset.shape[0]):\n",
    "        subset_list = [[],[],[]]\n",
    "        for j in range(dataset.shape[1]):\n",
    "            subset_list[int(dataset[i,j])].append(j)\n",
    "        newEntropy = 0.0\n",
    "        splitInfo = 0.0\n",
    "        for value in [0,1,2]:\n",
    "            if len(subset_list[value])==0:\n",
    "                continue\n",
    "            prob = len(subset_list[value])/float(dataset.shape[1])\n",
    "            newEntropy += prob * calcShannonEnt(Y[subset_list[value]])\n",
    "            splitInfo += -prob * log(prob, 2)\n",
    "        infoGain = baseEntropy - newEntropy\n",
    "        if (splitInfo == 0):\n",
    "            continue\n",
    "        infoGainRatio = infoGain / splitInfo\n",
    "        InfoGain_list.append(infoGainRatio)\n",
    "    return InfoGain_list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "headed-harmony",
   "metadata": {},
   "outputs": [],
   "source": [
    "InfoGain_list = calcInfoGain(train,train_Y)\n",
    "rank_infoGain = np.array(InfoGain_list).argsort()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "russian-disposition",
   "metadata": {},
   "outputs": [],
   "source": [
    "for i in [100,500,1000,5000,10000]:\n",
    "    simple_SVM(train[rank_infoGain[-i:],:].T,train_Y,test[rank_infoGain[-i:],:].T,test_Y)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "liked-packet",
   "metadata": {},
   "source": [
    "## Random selection can even work well!!!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "daily-consent",
   "metadata": {},
   "outputs": [],
   "source": [
    "import random\n",
    "\n",
    "rl = random.sample(range(28622), 5000)\n",
    "simple_SVM(train[rl,:].T,train_Y,test[rl,:].T,test_Y)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
